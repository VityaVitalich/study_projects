{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Mart vs KNN vs SVD\n",
    "\n",
    "Ниже посмотрим на качество ранжирования с помощью LambdaMart на задаче MQ, на различные метрики ранжирования, а также на LambdaMart + KNN против SVD, на задаче MovieLens\n",
    "\n",
    "Все данные можно найти здесь https://onedrive.live.com/?authkey=%21ACnoZZSZVfHPJd0&id=8FEADC23D838BDA8%21107&cid=8FEADC23D838BDA8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from knn_inherited import KNNMeans, KNNBasic\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "\n",
    "from svd import SVD\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import LETOR\n",
    "\n",
    "\n",
    "seed = 0xAB0BA\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQ2007\n",
    "\n",
    "Рассмотрим сначала датасет 2007 года, посчитаем на изначальном датасете все метрики и посмотрим сколько мы сможем выбить нашим LambdaMart-ом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_2007.txt', sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переделаем под удобный вид, обзовем колонки приятными именами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = df[56]\n",
    "doc_id = df[50]\n",
    "df = df.iloc[:,:48]\n",
    "df['doc_id'] = doc_id\n",
    "for i in range(1, 48):\n",
    "    df[i] = df[i].str.split(':').str[1]\n",
    "    df[i] = df[i].astype(float)\n",
    "    \n",
    "df[1] = df[1].astype(int)\n",
    "df['prev_res'] = prob\n",
    "\n",
    "names = ['relevance', 'query_id']\n",
    "for i in range(2, 48):\n",
    "    names.append('feature' + str(i))\n",
    "    \n",
    "names.append('doc_id')\n",
    "names.append('prev_res')\n",
    "\n",
    "df.columns = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>query_id</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature40</th>\n",
       "      <th>feature41</th>\n",
       "      <th>feature42</th>\n",
       "      <th>feature43</th>\n",
       "      <th>feature44</th>\n",
       "      <th>feature45</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>prev_res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GX000-00-0000000</td>\n",
       "      <td>0.024691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.031310</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.033206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823908</td>\n",
       "      <td>0.750092</td>\n",
       "      <td>0.385426</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GX000-24-12369390</td>\n",
       "      <td>0.416367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.078682</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.080022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868557</td>\n",
       "      <td>0.641385</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.074713</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GX000-62-7863450</td>\n",
       "      <td>0.568950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.019058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.022591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863460</td>\n",
       "      <td>0.016642</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GX016-48-5543459</td>\n",
       "      <td>0.775913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.039477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.040555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769845</td>\n",
       "      <td>0.646567</td>\n",
       "      <td>0.073711</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.218391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GX037-87-3082362</td>\n",
       "      <td>0.334800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevance  query_id  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0          0        10  0.000000  0.000000      0.00  0.000000  0.000000   \n",
       "1          1        10  0.031310  0.666667      0.50  0.166667  0.033206   \n",
       "2          1        10  0.078682  0.166667      0.50  0.333333  0.080022   \n",
       "3          1        10  0.019058  1.000000      1.00  0.500000  0.022591   \n",
       "4          0        10  0.039477  0.000000      0.75  0.166667  0.040555   \n",
       "\n",
       "   feature7  feature8  feature9  ...  feature40  feature41  feature42  \\\n",
       "0       0.0       0.0       0.0  ...   0.000000   0.000000   0.000000   \n",
       "1       0.0       0.0       0.0  ...   0.823908   0.750092   0.385426   \n",
       "2       0.0       0.0       0.0  ...   0.868557   0.641385   0.010462   \n",
       "3       0.0       0.0       0.0  ...   1.000000   0.863460   0.016642   \n",
       "4       0.0       0.0       0.0  ...   0.769845   0.646567   0.073711   \n",
       "\n",
       "   feature43  feature44  feature45  feature46  feature47             doc_id  \\\n",
       "0   0.000000   0.017241   0.000000   0.000000        0.0   GX000-00-0000000   \n",
       "1   0.923077   0.086207   0.333333   0.448276        0.0  GX000-24-12369390   \n",
       "2   0.076923   0.074713   0.833333   0.678161        0.0   GX000-62-7863450   \n",
       "3   0.153846   0.040230   0.833333   0.896552        0.0   GX016-48-5543459   \n",
       "4   0.076923   0.034483   0.333333   0.218391        0.0   GX037-87-3082362   \n",
       "\n",
       "   prev_res  \n",
       "0  0.024691  \n",
       "1  0.416367  \n",
       "2  0.568950  \n",
       "3  0.775913  \n",
       "4  0.334800  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборку на тренировочную и тестовую в соотношение 4 к 1. Будем делить по запросам, чтобы ничего не сломать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df['query_id'].unique())\n",
    "train_idx = np.random.choice(df['query_id'].unique().astype(int), int(n*0.8), replace=False)\n",
    "\n",
    "df_train = df.loc[df['query_id'].isin(train_idx)]\n",
    "df_test = df.loc[~(df['query_id'].isin(train_idx))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем метрики MRR, MAP и усредненный nDCG по всем запросам. Примем за ответ признак prob от авторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      " MRR =  0.5801735839060365 \n",
      " MAP@10 =  0.31203576797672744 \n",
      " mean nDCG@10 =  0.5043703263095799\n",
      "---------\n",
      "Test metrics\n",
      " MRR =  0.6080969858243465 \n",
      " MAP@10 =  0.30883267195767194 \n",
      " mean nDCG@10 =  0.5057646751681216\n"
     ]
    }
   ],
   "source": [
    "print('Train metrics')\n",
    "print(' MRR = ', LETOR.MRR(df_train), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(df_train, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(df_train, 10))\n",
    "\n",
    "print('---------')\n",
    "print('Test metrics')\n",
    "print(' MRR = ', LETOR.MRR(df_test), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(df_test, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(df_test, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь обучим Лямбду март и посмотрим на качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_mart = LETOR.LambdaMart(n_trees = 5)\n",
    "lambda_mart.fit(df_train, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = lambda_mart.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      " MRR =  0.548924337761267 \n",
      " MAP@10 =  0.27663362228860383 \n",
      " mean nDCG@10 =  0.47261973821990033\n",
      "---------\n",
      "Test metrics\n",
      " MRR =  0.5482820855977371 \n",
      " MAP@10 =  0.2786142234671647 \n",
      " mean nDCG@10 =  0.4737965854369945\n"
     ]
    }
   ],
   "source": [
    "print('Train metrics')\n",
    "print(' MRR = ', LETOR.MRR(lambda_mart.X), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(lambda_mart.X, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(lambda_mart.X, 10))\n",
    "\n",
    "print('---------')\n",
    "print('Test metrics')\n",
    "print(' MRR = ', LETOR.MRR(X_pred), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(X_pred, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(X_pred, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши метрики немного хуже, но не сильно! И кажется без всяких трюков и подбора гиперпараметров это уже неплохой результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQ2008\n",
    "\n",
    "Посмотрим все то же самое на датасете 2008 года"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_2008.txt', sep=\" \", header=None)\n",
    "\n",
    "prob = df[56]\n",
    "doc_id = df[50]\n",
    "df = df.iloc[:,:48]\n",
    "df['doc_id'] = doc_id\n",
    "for i in range(1, 48):\n",
    "    df[i] = df[i].str.split(':').str[1]\n",
    "    df[i] = df[i].astype(float)\n",
    "    \n",
    "df[1] = df[1].astype(int)\n",
    "df['prev_res'] = prob\n",
    "\n",
    "names = ['relevance', 'query_id']\n",
    "for i in range(2, 48):\n",
    "    names.append('feature' + str(i))\n",
    "    \n",
    "names.append('doc_id')\n",
    "names.append('prev_res')\n",
    "\n",
    "df.columns = names\n",
    "\n",
    "n = len(df['query_id'].unique())\n",
    "train_idx = np.random.choice(df['query_id'].unique().astype(int), int(n*0.8), replace=False)\n",
    "\n",
    "df_train = df.loc[df['query_id'].isin(train_idx)]\n",
    "df_test = df.loc[~(df['query_id'].isin(train_idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      " MRR =  0.568728429865887 \n",
      " MAP@10 =  0.22934807256235828 \n",
      " mean nDCG@10 =  0.45867450651825253\n",
      "---------\n",
      "Test metrics\n",
      " MRR =  0.505518341307815 \n",
      " MAP@10 =  0.21933603353622141 \n",
      " mean nDCG@10 =  0.4353952936603141\n"
     ]
    }
   ],
   "source": [
    "print('Train metrics')\n",
    "print(' MRR = ', LETOR.MRR(df_train), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(df_train, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(df_train, 10))\n",
    "\n",
    "print('---------')\n",
    "print('Test metrics')\n",
    "print(' MRR = ', LETOR.MRR(df_test), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(df_test, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(df_test, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_mart = LETOR.LambdaMart(n_trees = 5)\n",
    "lambda_mart.fit(df_train, verbose = False)\n",
    "X_pred = lambda_mart.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      " MRR =  0.539969078123445 \n",
      " MAP@10 =  0.21360552886934914 \n",
      " mean nDCG@10 =  0.4263591140635728\n",
      "---------\n",
      "Test metrics\n",
      " MRR =  0.4758685947695236 \n",
      " MAP@10 =  0.1955658193101802 \n",
      " mean nDCG@10 =  0.3982563091902146\n"
     ]
    }
   ],
   "source": [
    "print('Train metrics')\n",
    "print(' MRR = ', LETOR.MRR(lambda_mart.X), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(lambda_mart.X, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(lambda_mart.X, 10))\n",
    "\n",
    "print('---------')\n",
    "print('Test metrics')\n",
    "print(' MRR = ', LETOR.MRR(X_pred), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(X_pred, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(X_pred, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом датасете изначально метрики немного хуже. Соответственно и на нашей модели они немного хуже. Что в том, что в этом разрыв примерно одинаковый"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens\n",
    "\n",
    "Теперь рассмотрим датасет с фильмами. если оценка 5, тогда релевантность 2, если оценка 4 тогда релевантность 1, иначе 0.\n",
    "\n",
    "Теперь наша задача привести датасет к тому виду, который может сьесть наш Лямбда март. Будем думать о юзерах как о запросах, мол они запрашивают какой фильм они хотели бы посмотреть, а мы должны им порекомендовать. В качестве документа выступит конкретный фильм, который будет релевантный или нет. Признаки нам нужны для запроса, соответственно это будет у юзера его среднее по всем фильмам, разброс по всем фильмам, минимальная оценка и максимальная. Конечно наши признаки должны отображать признак соотношение запрос-документ, в нашем случае пользователь-фильм. Первое что приходит в голову - это найти соседей этого пользователя, посчитать по соседям средние и использовать это. Сделаем сначала простые признаки фильмов, а затем признаки из КННа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user item  rating  timestamp\n",
       "0  196  242     3.0  881250949\n",
       "1  186  302     3.0  891717742\n",
       "2   22  377     1.0  878887116\n",
       "3  244   51     2.0  880606923\n",
       "4  166  346     1.0  886397596"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Dataset.load_builtin('ml-100k')\n",
    "df = pd.DataFrame(data.raw_ratings)\n",
    "df.columns = ['user', 'item', 'rating', 'timestamp']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_means = df.groupby('user').mean()['rating']\n",
    "user_sd = df.groupby('user').std()['rating']\n",
    "user_min = df.groupby('user').min()['rating']\n",
    "user_max = df.groupby('user').max()['rating']\n",
    "\n",
    "features = user_means.to_frame().merge(user_sd.to_frame(), on='user')\n",
    "features = features.merge(user_min.to_frame(), on='user')\n",
    "features = features.merge(user_max.to_frame(), on='user')\n",
    "features.columns = ['feature1', 'feature2', 'feature3', 'feature4']\n",
    "features.index.name = 'query_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['timestamp'])\n",
    "df.columns = ['query_id', 'doc_id', 'relevance']\n",
    "df['relevance'][(df['relevance'] < 4)] = 0\n",
    "df['relevance'][(df['relevance'] == 4)] = 1\n",
    "df['relevance'][(df['relevance'] == 5)] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(features, on='query_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>1.016065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.413043</td>\n",
       "      <td>1.223867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351562</td>\n",
       "      <td>1.493239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.651261</td>\n",
       "      <td>1.071406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>1.431782</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.426630</td>\n",
       "      <td>0.982156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.888476</td>\n",
       "      <td>1.041408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.465251</td>\n",
       "      <td>1.017140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.097484</td>\n",
       "      <td>1.416414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.392157</td>\n",
       "      <td>0.776619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query_id doc_id  relevance  feature1  feature2  feature3  feature4\n",
       "0          196    242        0.0  3.615385  1.016065       1.0       5.0\n",
       "1          186    302        0.0  3.413043  1.223867       1.0       5.0\n",
       "2           22    377        0.0  3.351562  1.493239       1.0       5.0\n",
       "3          244     51        0.0  3.651261  1.071406       1.0       5.0\n",
       "4          166    346        0.0  3.550000  1.431782       1.0       5.0\n",
       "...        ...    ...        ...       ...       ...       ...       ...\n",
       "99995      880    476        0.0  3.426630  0.982156       1.0       5.0\n",
       "99996      716    204        2.0  3.888476  1.041408       1.0       5.0\n",
       "99997      276   1090        0.0  3.465251  1.017140       1.0       5.0\n",
       "99998       13    225        0.0  3.097484  1.416414       1.0       5.0\n",
       "99999       12    203        0.0  4.392157  0.776619       1.0       5.0\n",
       "\n",
       "[100000 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет просто огромный для тех операций которые мы здесь делаем, на полном у меня упало ядро. Поэтому случайно выберем 200 фильмов которым повезло оказаться в нашей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc_id'] = df['doc_id'].astype(int)\n",
    "m = len(df['doc_id'].unique())\n",
    "lucky_docs = np.random.choice(df['doc_id'].unique().astype(int), 200, replace=False)\n",
    "df = df[(df['doc_id'].isin(lucky_docs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>1.016065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>115</td>\n",
       "      <td>265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.934783</td>\n",
       "      <td>1.174868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>305</td>\n",
       "      <td>451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.409910</td>\n",
       "      <td>1.079840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>210</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.060606</td>\n",
       "      <td>0.817346</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>299</td>\n",
       "      <td>144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.464286</td>\n",
       "      <td>0.907245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99942</th>\n",
       "      <td>363</td>\n",
       "      <td>181</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.054662</td>\n",
       "      <td>1.280210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99953</th>\n",
       "      <td>655</td>\n",
       "      <td>913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.908029</td>\n",
       "      <td>0.732701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99958</th>\n",
       "      <td>394</td>\n",
       "      <td>380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.859060</td>\n",
       "      <td>0.937364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99960</th>\n",
       "      <td>621</td>\n",
       "      <td>809</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.549708</td>\n",
       "      <td>1.052525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99961</th>\n",
       "      <td>766</td>\n",
       "      <td>91</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.354286</td>\n",
       "      <td>0.837464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11990 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query_id  doc_id  relevance  feature1  feature2  feature3  feature4\n",
       "0          196     242        0.0  3.615385  1.016065       1.0       5.0\n",
       "6          115     265        0.0  3.934783  1.174868       1.0       5.0\n",
       "8          305     451        0.0  3.409910  1.079840       1.0       5.0\n",
       "13         210      40        0.0  4.060606  0.817346       2.0       5.0\n",
       "22         299     144        1.0  3.464286  0.907245       1.0       5.0\n",
       "...        ...     ...        ...       ...       ...       ...       ...\n",
       "99942      363     181        2.0  3.054662  1.280210       1.0       5.0\n",
       "99953      655     913        1.0  2.908029  0.732701       1.0       5.0\n",
       "99958      394     380        1.0  3.859060  0.937364       1.0       5.0\n",
       "99960      621     809        1.0  3.549708  1.052525       1.0       5.0\n",
       "99961      766      91        2.0  3.354286  0.837464       1.0       5.0\n",
       "\n",
       "[11990 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['query_id'] = df['query_id'].astype(int)\n",
    "n = len(df['query_id'].unique())\n",
    "train_idx = np.random.choice(df['query_id'].unique().astype(int), int(n*0.8), replace=False)\n",
    "\n",
    "df_train = df.loc[df['query_id'].isin(train_idx)]\n",
    "df_test = df.loc[~(df['query_id'].isin(train_idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iteration nDCGs == 0.39290276756423886 \n",
      "1 iteration nDCGs == 0.39290276756423886 \n",
      "2 iteration nDCGs == 0.39290276756423886 \n",
      "3 iteration nDCGs == 0.39290276756423886 \n",
      "4 iteration nDCGs == 0.39290276756423886 \n",
      "5 iteration nDCGs == 0.39290276756423886 \n",
      "6 iteration nDCGs == 0.39290276756423886 \n",
      "7 iteration nDCGs == 0.39290276756423886 \n",
      "8 iteration nDCGs == 0.39290276756423886 \n",
      "9 iteration nDCGs == 0.39290276756423886 \n"
     ]
    }
   ],
   "source": [
    "lambda_mart = LETOR.LambdaMart(n_trees = 10, max_depth = 7, max_rank=2)\n",
    "lambda_mart.fit(df_train, verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно с такими признаками мы даже не учимся, они видимо совсем неинформативные. Теперь будем брать по нескольким соседям средние и по ним предсказывать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNBasic(3)\n",
    "rating_matrix = df.pivot(index='query_id',\n",
    "        columns='doc_id',\n",
    "        values='relevance').fillna(0)\n",
    "\n",
    "knn.fit(rating_matrix)\n",
    "knn.fill_matrix()\n",
    "n3 = knn.y_df\n",
    "melted_n3 = n3.melt(ignore_index=False).dropna()\n",
    "\n",
    "df = df.merge(melted_n3, on=['query_id', 'doc_id'], how='left')\n",
    "df.columns = ['query_id', 'doc_id', 'relevance', 'feature1', 'feature2', 'feature3',\n",
    "       'feature4', 'feature5']\n",
    "df['feature5'] = df['feature5'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['query_id'] = df['query_id'].astype(int)\n",
    "n = len(df['query_id'].unique())\n",
    "train_idx = np.random.choice(df['query_id'].unique().astype(int), int(n*0.8), replace=False)\n",
    "\n",
    "df_train = df.loc[df['query_id'].isin(train_idx)]\n",
    "df_test = df.loc[~(df['query_id'].isin(train_idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iteration nDCGs == 0.38687565567014154 \n",
      "1 iteration nDCGs == 0.5641782969472084 \n",
      "2 iteration nDCGs == 0.5639973028390454 \n",
      "3 iteration nDCGs == 0.5639973028390454 \n",
      "4 iteration nDCGs == 0.5640212588167981 \n",
      "5 iteration nDCGs == 0.5640212588167981 \n",
      "6 iteration nDCGs == 0.5640212588167981 \n",
      "7 iteration nDCGs == 0.5640212588167981 \n",
      "8 iteration nDCGs == 0.5640212588167981 \n",
      "9 iteration nDCGs == 0.5640212588167981 \n"
     ]
    }
   ],
   "source": [
    "lambda_mart = LETOR.LambdaMart(n_trees = 10, max_depth = 5, max_rank=2)\n",
    "lambda_mart.fit(df_train, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что уже учимся, попробуем добавить признаков с нескольких соседей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNBasic(5)\n",
    "rating_matrix = df.pivot(index='query_id',\n",
    "        columns='doc_id',\n",
    "        values='relevance').fillna(0)\n",
    "\n",
    "knn.fit(rating_matrix)\n",
    "knn.fill_matrix()\n",
    "n5 = knn.y_df\n",
    "melted_n5 = n5.melt(ignore_index=False).dropna()\n",
    "\n",
    "df = df.merge(melted_n5, on=['query_id', 'doc_id'], how='left')\n",
    "df.columns = ['query_id', 'doc_id', 'relevance', 'feature1', 'feature2', 'feature3',\n",
    "       'feature4', 'feature5', 'feature6']\n",
    "df['feature6'] = df['feature6'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNBasic(7)\n",
    "rating_matrix = df.pivot(index='query_id',\n",
    "        columns='doc_id',\n",
    "        values='relevance').fillna(0)\n",
    "\n",
    "knn.fit(rating_matrix)\n",
    "knn.fill_matrix()\n",
    "n7 = knn.y_df\n",
    "melted_n7 = n7.melt(ignore_index=False).dropna()\n",
    "\n",
    "df = df.merge(melted_n7, on=['query_id', 'doc_id'], how='left')\n",
    "df.columns = ['query_id', 'doc_id', 'relevance', 'feature1', 'feature2', 'feature3',\n",
    "       'feature4', 'feature5', 'feature6', 'feature7']\n",
    "df['feature7'] = df['feature7'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['query_id'] = df['query_id'].astype(int)\n",
    "n = len(df['query_id'].unique())\n",
    "train_idx = np.random.choice(df['query_id'].unique().astype(int), int(n*0.8), replace=False)\n",
    "\n",
    "df_train = df.loc[df['query_id'].isin(train_idx)]\n",
    "df_test = df.loc[~(df['query_id'].isin(train_idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iteration nDCGs == 0.39043589925081096 \n",
      "1 iteration nDCGs == 0.5773145854226704 \n",
      "2 iteration nDCGs == 0.5778621846973017 \n",
      "3 iteration nDCGs == 0.5780527861062831 \n",
      "4 iteration nDCGs == 0.5780527861062831 \n",
      "5 iteration nDCGs == 0.5781006787975719 \n",
      "6 iteration nDCGs == 0.5781006787975719 \n",
      "7 iteration nDCGs == 0.5777412204613096 \n",
      "8 iteration nDCGs == 0.5777412204613096 \n",
      "9 iteration nDCGs == 0.5777412204613096 \n"
     ]
    }
   ],
   "source": [
    "lambda_mart = LETOR.LambdaMart(n_trees = 10, max_depth=5, max_rank=2)\n",
    "lambda_mart.fit(df_train, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество поднялось но не сильно, признаки среднего все еще слишком слабые, а информации о соседей в количестве одного признака вполне достаточно. Думаю, такой метод бы работал, если бы мы знали что-то еще о фильмах. Описание или какие то такие признаки. Могли бы искать расстояние между эмбеддингами, доставать энтити и прочее. Посмотрим все же, как оно на тесте и другие метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = lambda_mart.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics @ 10\n",
      " MRR =  0.8854054054054055 \n",
      " MAP@10 =  0.6128931071803095 \n",
      " mean nDCG@10 =  0.5438161837481544\n",
      "---------\n",
      "Test metrics @ 10\n",
      " MRR =  0.8797297297297297 \n",
      " MAP@10 =  0.6251744874125826 \n",
      " mean nDCG@10 =  0.5551719508534374\n"
     ]
    }
   ],
   "source": [
    "print('Train metrics @ 10')\n",
    "print(' MRR = ', LETOR.MRR(lambda_mart.X), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(lambda_mart.X, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(lambda_mart.X, 10, 2))\n",
    "\n",
    "print('---------')\n",
    "print('Test metrics @ 10')\n",
    "print(' MRR = ', LETOR.MRR(X_pred), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(X_pred, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(X_pred, 10, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тем не менее остальные метрики весьма хорошие, лучше чем на прошлом. Но кажется это специфика задачи, здесь нам как будто бы 1) проще попасть с фильмами, больше релевантных 2) мы использовали КНН, который дает нам уже почти ответ на нашу задачу, а точнее раньше давал ответ на задачу рекомендации по 5 бальной шкале, и вообще восстанавливал оценки для каждого фильма\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь используется алгоритм SVD, поэтому попробуем взять целый датасет и посмотрим. Исходя из прошлой работы будем использовать алгоритм SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06523771997530782\n"
     ]
    }
   ],
   "source": [
    "data = Dataset.load_builtin('ml-100k')\n",
    "df = pd.DataFrame(data.raw_ratings)\n",
    "df.columns = ['user', 'item', 'rating', 'timestamp']\n",
    "\n",
    "df = df.drop(columns=['timestamp'])\n",
    "df['rating'][(df['rating'] < 4)] = 0\n",
    "df['rating'][(df['rating'] == 4)] = 1\n",
    "df['rating'][(df['rating'] == 5)] = 2\n",
    "\n",
    "df['user'] = df['user'].astype(int)\n",
    "n = len(df['user'].unique())\n",
    "train_idx = np.random.choice(df['user'].unique().astype(int), int(n*0.8), replace=False)\n",
    "\n",
    "df_train = df.loc[df['user'].isin(train_idx)]\n",
    "df_test = df.loc[~(df['user'].isin(train_idx))]\n",
    "\n",
    "svd = SVD(15)\n",
    "svd.fit(df_train, algo='sgd', verbose=None)\n",
    "\n",
    "y_pred, y_test = svd.predict(df_test)\n",
    "df_test['prev_res'] = y_pred\n",
    "df_test.columns = ['query_id', 'doc_id', 'relevance', 'prev_res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_test = svd.predict(df_train)\n",
    "df_train['prev_res'] = y_pred\n",
    "df_train.columns = ['query_id', 'doc_id', 'relevance', 'prev_res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics @ 10\n",
      " MRR =  0.7810324254289771 \n",
      " MAP@10 =  0.4797733779630331 \n",
      " mean nDCG@10 =  0.4502959617529576\n",
      "---------\n",
      "Test metrics @ 10\n",
      " MRR =  0.7812673217435123 \n",
      " MAP@10 =  0.4480179726211472 \n",
      " mean nDCG@10 =  0.4225930413134915\n"
     ]
    }
   ],
   "source": [
    "print('Train metrics @ 10')\n",
    "print(' MRR = ', LETOR.MRR(df_train), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(df_train, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(df_train, 10, 2))\n",
    "\n",
    "print('---------')\n",
    "print('Test metrics @ 10')\n",
    "print(' MRR = ', LETOR.MRR(df_test), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(df_test, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(df_test, 10, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим качество на топ 10 фильмах на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics @ 10 KNN+LambdaMart\n",
      " MRR =  0.8797297297297297 \n",
      " MAP@10 =  0.6251744874125826 \n",
      " mean nDCG@10 =  0.5551719508534374\n",
      "---------\n",
      "Test metrics @ 10 SVD\n",
      " MRR =  0.7812673217435123 \n",
      " MAP@10 =  0.4480179726211472 \n",
      " mean nDCG@10 =  0.4225930413134915\n"
     ]
    }
   ],
   "source": [
    "print('Test metrics @ 10 KNN+LambdaMart')\n",
    "print(' MRR = ', LETOR.MRR(X_pred), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(X_pred, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(X_pred, 10, 2))\n",
    "\n",
    "\n",
    "print('---------')\n",
    "print('Test metrics @ 10 SVD')\n",
    "print(' MRR = ', LETOR.MRR(df_test), '\\n',\n",
    "      'MAP@10 = ', LETOR.MAP(df_test, 10), '\\n',\n",
    "      'mean nDCG@10 = ', LETOR.mean_nDCG(df_test, 10, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "по всем метрикам на топ10 фильмах выигрывает кнн и лямбда март. Посмотрим на топ 5 фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics @ 5 KNN + LambdaMart\n",
      " MRR =  0.8797297297297297 \n",
      " MAP@5 =  0.6807237237237238 \n",
      " mean nDCG@5 =  0.6176424813557154\n",
      "---------\n",
      "Test metrics @ 5 SVD\n",
      " MRR =  0.7812673217435123 \n",
      " MAP@5 =  0.5022222222222222 \n",
      " mean nDCG@5 =  0.4343452176046694\n"
     ]
    }
   ],
   "source": [
    "print('Test metrics @ 5 KNN + LambdaMart')\n",
    "print(' MRR = ', LETOR.MRR(X_pred), '\\n',\n",
    "      'MAP@5 = ', LETOR.MAP(X_pred, 5), '\\n',\n",
    "      'mean nDCG@5 = ', LETOR.mean_nDCG(X_pred, 5, 2))\n",
    "\n",
    "\n",
    "print('---------')\n",
    "print('Test metrics @ 5 SVD')\n",
    "print(' MRR = ', LETOR.MRR(df_test), '\\n',\n",
    "      'MAP@5 = ', LETOR.MAP(df_test, 5), '\\n',\n",
    "      'mean nDCG@5 = ', LETOR.mean_nDCG(df_test, 5, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что КНН с лямбда мартом опять оказался лучше. При этом видим, что nDCG и MAP вырос у алгоритма лямбда март сильнее. Теперь посмотрим на топ-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics @ 3 KNN + LambdaMart\n",
      " MRR =  0.8797297297297297 \n",
      " MAP@3 =  0.7385885885885886 \n",
      " mean nDCG@3 =  0.6704034467206315\n",
      "---------\n",
      "Test metrics @ 3 SVD\n",
      " MRR =  0.7812673217435123 \n",
      " MAP@3 =  0.5511463844797178 \n",
      " mean nDCG@3 =  0.4419614882221018\n"
     ]
    }
   ],
   "source": [
    "print('Test metrics @ 3 KNN + LambdaMart')\n",
    "print(' MRR = ', LETOR.MRR(X_pred), '\\n',\n",
    "      'MAP@3 = ', LETOR.MAP(X_pred, 3), '\\n',\n",
    "      'mean nDCG@3 = ', LETOR.mean_nDCG(X_pred, 3, 2))\n",
    "\n",
    "print('---------')\n",
    "\n",
    "print('Test metrics @ 3 SVD')\n",
    "print(' MRR = ', LETOR.MRR(df_test), '\\n',\n",
    "      'MAP@3 = ', LETOR.MAP(df_test, 3), '\\n',\n",
    "      'mean nDCG@3 = ', LETOR.mean_nDCG(df_test, 3, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "опять же метрики лучше у первого алгоритма. Видим, что на 3 обьектах nDCG становится еще лучше и MAP тоже, однако nDCG не стал сильно лучше у SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что на lambdamart с кнн в качестве признаков качество выше. Этому есть 3 обьяснения. 1) в предыдущих работах на тему этого датасета получалось то же самое. Скорее всего это связано со спецификой данных, возможно с небольшим количеством данных, что нам проще искать соседей. 2) в алгоритме с лямбда мартом мы обучаем алгоритм непосредственно на nDCG и смотрим что будет при перестановках в ранжированном списке, как изменится наша метрика. 3) Поверх результатов КНН с разными параметрами обучаем еще и бустинг из деревьев. Как правило на табличных данных бустинг сильно бьет другие алгоритмы (кроме возможно случайных лесов). Таким образом, мы учли сразу несколько соседей как будто бы. В случае SVD мы не пользуемся дополнительными признаками, а пытаемся предсказывать рейтинг как было в прошлый раз просто через разложение, в такой постановке алгоритм очевидно будет слабее чем lambdaMart в связке с KNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
