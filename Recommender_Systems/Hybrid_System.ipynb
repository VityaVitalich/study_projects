{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujsL3Dzxnmrj",
    "outputId": "c32b34c1-43a1-484d-9dc7-1216e7069128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting surprise\n",
      "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
      "Collecting scikit-surprise\n",
      "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
      "\u001b[K     |████████████████████████████████| 771 kB 7.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.7.3)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp38-cp38-linux_x86_64.whl size=2626467 sha256=fbb1d81c377fa26b4d85ab6bbf102f6a05e8e8ede2f411e2d4da20235198084d\n",
      "  Stored in directory: /root/.cache/pip/wheels/af/db/86/2c18183a80ba05da35bf0fb7417aac5cddbd93bcb1b92fd3ea\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "Successfully installed scikit-surprise-1.1.3 surprise-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install surprise\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 0xAB0BA\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gnhd0qKIn6oI",
    "outputId": "93992633-137f-403d-db03-ff9bb32c7baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0MFF5DMnmrw"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/content/drive/MyDrive/RecSys'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFbeGbExnmry"
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, 'ratings.csv'),\n",
    "    dtype={\n",
    "        'element_uid': np.uint16,\n",
    "        'user_uid': np.uint32,\n",
    "        'ts': np.float64,\n",
    "        'rating': np.uint8\n",
    "    }\n",
    ")\n",
    "\n",
    "ratings = ratings.sort_values(by=['ts'])\n",
    "ratings.index=np.arange(len(ratings))\n",
    "\n",
    "\n",
    "le_users = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "le_items = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "ratings['user_uid'] = le_users.fit_transform(ratings['user_uid'].values.reshape(-1,1))\n",
    "ratings['element_uid'] = le_items.fit_transform(ratings['element_uid'].values.reshape(-1,1))\n",
    "\n",
    "ratings['user_uid'] = ratings['user_uid'].astype(int)\n",
    "ratings['element_uid'] = ratings['element_uid'].astype(int)\n",
    "\n",
    "max_uid = ratings['user_uid'].max()\n",
    "max_iid = ratings['element_uid'].max()\n",
    "\n",
    "ratings.columns = ['user', 'item', 'rating', 'ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2Qc-iDlnmr0"
   },
   "outputs": [],
   "source": [
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(ratings[[\"user\", \"item\", \"rating\"]], reader)\n",
    "\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.30, random_state=999, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KFZJy0pnmr2"
   },
   "source": [
    "# Считаем метрики SVD\n",
    "\n",
    "\n",
    "Ниже рассмотрим несколько параметров для факторов SVD и помимо RMSE посчитаем еще и Accuracy после округления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sj8cu6Fanmr6",
    "outputId": "e1e7aa2f-4501-44aa-eaba-fc8d7f6d6d89"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:24<02:54, 24.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.8228  1.8234  1.8218  1.8227  0.0006  \n",
      "Fit time          4.51    4.20    3.92    4.21    0.24    \n",
      "Test time         2.48    2.17    2.12    2.26    0.16    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [00:47<02:21, 23.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.8380  1.8359  1.8332  1.8357  0.0019  \n",
      "Fit time          4.03    3.74    4.04    3.93    0.14    \n",
      "Test time         1.29    2.14    2.04    1.83    0.38    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [01:11<01:58, 23.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.8466  1.8421  1.8388  1.8425  0.0032  \n",
      "Fit time          4.17    3.88    4.44    4.17    0.23    \n",
      "Test time         2.31    1.33    2.32    1.99    0.46    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [01:34<01:33, 23.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.8537  1.8464  1.8491  1.8497  0.0030  \n",
      "Fit time          4.31    4.06    4.37    4.25    0.14    \n",
      "Test time         2.17    2.05    2.17    2.13    0.06    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [01:58<01:11, 23.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.8483  1.8507  1.8534  1.8508  0.0021  \n",
      "Fit time          4.38    4.31    4.44    4.38    0.05    \n",
      "Test time         2.08    2.09    2.18    2.12    0.05    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [02:22<00:47, 23.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.8517  1.8483  1.8582  1.8527  0.0041  \n",
      "Fit time          4.17    4.46    4.48    4.37    0.14    \n",
      "Test time         2.07    2.31    2.16    2.18    0.10    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [02:48<00:24, 24.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.8573  1.8482  1.8538  1.8531  0.0037  \n",
      "Fit time          4.56    4.32    5.51    4.80    0.51    \n",
      "Test time         2.30    2.18    2.35    2.28    0.07    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [03:22<00:00, 25.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.8649  1.8570  1.8502  1.8573  0.0060  \n",
      "Fit time          7.74    7.75    7.69    7.73    0.02    \n",
      "Test time         2.18    1.35    2.10    1.88    0.37    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_comp = [1,3,5,8,10,12,15, 100]\n",
    "res_rmse = []\n",
    "\n",
    "for n in tqdm(n_comp):\n",
    "\n",
    "    svd = SVD(n_factors = n)\n",
    "    \n",
    "    res = cross_validate(svd, data, measures=['RMSE'], cv=3, verbose=True)\n",
    "\n",
    "    res_rmse.append(np.mean(res['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "SvntLkb8nmr_",
    "outputId": "3a6ff05a-a772-49be-c7a3-dc8b14e2c09d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_comp[:-1], res_rmse[:-1], label='SVD SGD')\n",
    "plt.xticks(n_comp[:-1])\n",
    "plt.xlabel('N factors')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE dependency on N factors in SVD')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uy3dRt6HnmsD",
    "outputId": "4ee4ca53-69ee-4486-9182-19beec2fcca5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6164735418430938"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# константное предсказание средним по всему трейну\n",
    "\n",
    "all_y = [elem[2] for elem in testset]\n",
    "np.abs(all_y - trainset.global_mean).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9RFetL2nmsF",
    "outputId": "6a47a5c4-c9ce-4dc7-b660-05ba6f39597a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8111397251532624"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array(all_y) - 10).mean() #константное предсказание 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qfxx-c_nmsK"
   },
   "source": [
    "Видим, что почти вне зависимости от факторов наш алгоритм дает RMSE в районе 1.83. Это кажется относительно неплохим результатом, по поводу зависимости мы видим, что чем больше параметров, тем хуже наша модель предсказывает, хоть и на  немного хуже. Однако интересно заметить, что я выше попробовал предсказать константно 2 раза - в одном случае средним, в другом максимумом и получил RMSE лучше чем предсказанный алгоритмом. Странный тренд, видимо он связан с разницей во вкусах пользователей и распределением с сильным пиком. Я также специально проверил результат с 100 факторами и 1 фактором как крайние случаи. Оказалось, что в случае с 1 фактором мы получаем лучший результат, который к слову очень близко к константному 10 предсказанию. но хуже чем предсказание глобальным максимумом. А с 100 факторами самый плохой\n",
    "\n",
    "\n",
    "# NCF\n",
    "\n",
    "\n",
    "Для NCF с входными разложениями SVD создадим датасет, который в трейне будет все подсчитывать и на выходе давать вектора из P и Q матриц, а на тесте он будет обращаться к этим матрицам если он знает юзера/айтема, а если не знает то будет брать средний вектор по этой матрице. Конечно это не лучшее решение, в лучшем случае правда стоит заменять глобальным средним, как скажем это сделано в библиотеке Surprise. Но в этом случае, нам пришлось бы рассматривать отдельно этих пользователей и для них не строить предсказание сеткой, а отбирать предварительно, так как торчевская сетка не делает исключений для входящих обьектов :) \n",
    "\n",
    "В качестве сети будем использовать полносвязную сеть, на вход которой подаются компоненты SVD разложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FluvIK_dnmsL"
   },
   "outputs": [],
   "source": [
    "class Ratings(Dataset):\n",
    "    def __init__(self, df, split='train', svd=None, hidden_size=5):\n",
    "\n",
    "\n",
    "        if split == 'train':\n",
    "            self.df = df\n",
    "            self.iter_df = list(df.all_ratings())\n",
    "        else:\n",
    "            self.iter_df = df\n",
    "\n",
    "        if split == 'train':\n",
    "            self.svd = SVD(n_factors=hidden_size)\n",
    "            self.svd.fit(self.df)\n",
    "        else:\n",
    "            self.svd = svd\n",
    "            self.meanpu = self.svd.pu.mean(axis=0)\n",
    "            self.meanqi = self.svd.qi.mean(axis=0)\n",
    "\n",
    "\n",
    "    def __len__(self,):\n",
    "        \n",
    "        length = len(self.iter_df)\n",
    "\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.iter_df[idx]\n",
    "        r = torch.tensor(row[2])\n",
    "\n",
    "        user_id = row[0]\n",
    "        element_id = row[1]\n",
    "\n",
    "        try:\n",
    "            user_vector = self.svd.pu[user_id]\n",
    "        except IndexError:\n",
    "            user_vector = self.meanpu\n",
    "\n",
    "        try:\n",
    "            item_vector = self.svd.qi[element_id]\n",
    "        except IndexError:\n",
    "            item_vector = self.meanqi\n",
    "\n",
    "\n",
    "        return torch.from_numpy(user_vector).float(), torch.from_numpy(item_vector).float(), r.float()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZDAU1wqo_7v"
   },
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "\n",
    "    def __init__(self, hiddens, embedding_dim, activation_type='Relu'):\n",
    "        super(NCF, self).__init__()\n",
    "\n",
    "        model_hidden = []\n",
    "        self.hiddens = hiddens\n",
    "        n_layers = len(hiddens)\n",
    "        \n",
    "\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(embedding_dim*2, self.hiddens[0])\n",
    "\n",
    "        self.activation = torch.nn.ReLU(True)\n",
    "\n",
    "        for i in range(0, n_layers-1):\n",
    "            layer = nn.Sequential(nn.Dropout(p=0.3),\n",
    "          torch.nn.Linear(self.hiddens[i] ,self.hiddens[i+1]),\n",
    "          self.activation)\n",
    "            model_hidden.append(layer)\n",
    "\n",
    "        self.outLinear = nn.Linear(self.hiddens[-1], 1)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            self.linear1,\n",
    "            self.activation,\n",
    "            *model_hidden,\n",
    "            self.outLinear\n",
    "        )\n",
    "\n",
    "    def forward(self, user_x, item_x):\n",
    "\n",
    "\n",
    "        x = torch.cat((user_x, item_x), dim=1)\n",
    "        \n",
    "\n",
    "        out = self.net(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsllqp0PpNRK"
   },
   "outputs": [],
   "source": [
    "def run_epoch(stage, model, dataloader, loss_fn, optimizer, epoch, device):\n",
    "\n",
    "    if stage == \"train\":\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "    else:\n",
    "        torch.set_grad_enabled(False)\n",
    "        model.eval()\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    losses = []\n",
    "    for batch in tqdm(dataloader, total=len(dataloader), desc=f\"epoch: {str(epoch).zfill(3)} | {stage:5}\"):\n",
    "        uid, eid, r = batch\n",
    "\n",
    "        uid = uid.to(device)\n",
    "        eid = eid.to(device)\n",
    "\n",
    "                \n",
    "        r_pred = model(uid, eid)\n",
    "\n",
    "        #r = r.to(torch.float32)\n",
    "        loss = loss_fn(r_pred, r.to(device)) #.float()\n",
    "       # print(loss.float())\n",
    "\n",
    "        if stage == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "        losses.append(loss.detach().cpu().item())\n",
    "    \n",
    "\n",
    "    return np.sqrt(np.mean(losses))\n",
    "\n",
    "def run_experiment(model, dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, output_dir):\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    best_val_loss_epoch = -1\n",
    "    best_val_loss_fn = None\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = run_epoch(\"train\", model, dataloader_train, loss_fn, optimizer, epoch, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        val_loss = run_epoch(\"val\", model, dataloader_val, loss_fn, optimizer, epoch, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"epoch: {str(epoch).zfill(3)} | train_loss: {train_loss:5.3f}, val_loss: {val_loss:5.3f} (best: {best_val_loss:5.3f})\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "\n",
    "            best_val_loss = val_loss\n",
    "            best_val_loss_epoch = epoch\n",
    "\n",
    "            output_fn = os.path.join(output_dir, f\"epoch={str(epoch).zfill(2)}_valloss={best_val_loss:.3f}.pth.tar\")\n",
    "            save_checkpoint(model, output_fn)\n",
    "            print(f\"New checkpoint saved to {output_fn}\")\n",
    "\n",
    "            best_val_loss_fn = output_fn\n",
    "\n",
    "        print()\n",
    "\n",
    "    print (f\"Best val_loss = {best_val_loss:.3f} reached at epoch {best_val_loss_epoch}\")\n",
    "   # load_checkpoint(model, best_val_loss_fn)\n",
    "\n",
    "    return train_losses, val_losses, best_val_loss, model\n",
    "\n",
    "\n",
    "def save_checkpoint(model, filename):\n",
    "\n",
    "    with open(filename, \"wb\") as fp:\n",
    "        torch.save(model.state_dict(), fp)\n",
    "\n",
    "def load_checkpoint(model, filename):\n",
    "\n",
    "    with open(filename, \"rb\") as fp:\n",
    "        state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "    \n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLk2RqpDpzoM",
    "outputId": "ab289f8e-3fcd-4a87-ddd8-e275d9f93f8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train:   0%|          | 0/600 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | train:  99%|█████████▊| 592/600 [00:09<00:00, 87.73it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([465])) that is different to the input size (torch.Size([465, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | train: 100%|██████████| 600/600 [00:09<00:00, 64.38it/s]\n",
      "epoch: 000 | val  :  98%|█████████▊| 252/258 [00:02<00:00, 103.70it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([53])) that is different to the input size (torch.Size([53, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | val  : 100%|██████████| 258/258 [00:02<00:00, 98.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 3.474, val_loss: 2.082 (best:   inf)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=00_valloss=2.082.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 600/600 [00:07<00:00, 82.78it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 258/258 [00:02<00:00, 94.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 2.233, val_loss: 2.079 (best: 2.082)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=01_valloss=2.079.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 600/600 [00:07<00:00, 81.66it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 258/258 [00:02<00:00, 107.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 2.158, val_loss: 2.076 (best: 2.079)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=02_valloss=2.076.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 600/600 [00:07<00:00, 81.71it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 258/258 [00:02<00:00, 100.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 2.138, val_loss: 2.075 (best: 2.076)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=03_valloss=2.075.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 600/600 [00:07<00:00, 83.92it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 258/258 [00:02<00:00, 105.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 2.129, val_loss: 2.077 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 600/600 [00:07<00:00, 83.11it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 258/258 [00:02<00:00, 107.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 2.122, val_loss: 2.078 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 600/600 [00:07<00:00, 84.66it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 258/258 [00:02<00:00, 105.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 2.117, val_loss: 2.076 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 600/600 [00:07<00:00, 83.97it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 258/258 [00:02<00:00, 105.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.112, val_loss: 2.075 (best: 2.075)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=07_valloss=2.075.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 600/600 [00:07<00:00, 83.92it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 258/258 [00:02<00:00, 98.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.106, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 600/600 [00:07<00:00, 83.04it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 258/258 [00:02<00:00, 96.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.102, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 600/600 [00:07<00:00, 79.31it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 258/258 [00:05<00:00, 49.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.098, val_loss: 2.075 (best: 2.075)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=10_valloss=2.075.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 600/600 [00:09<00:00, 60.12it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 258/258 [00:02<00:00, 105.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.094, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 600/600 [00:07<00:00, 81.62it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 258/258 [00:03<00:00, 70.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.090, val_loss: 2.078 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 600/600 [00:07<00:00, 81.79it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 258/258 [00:02<00:00, 100.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.087, val_loss: 2.076 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 600/600 [00:07<00:00, 83.86it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 258/258 [00:02<00:00, 98.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.085, val_loss: 2.076 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 600/600 [00:07<00:00, 83.72it/s]\n",
      "epoch: 015 | val  : 100%|██████████| 258/258 [00:02<00:00, 97.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.082, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 600/600 [00:07<00:00, 82.97it/s]\n",
      "epoch: 016 | val  : 100%|██████████| 258/258 [00:02<00:00, 105.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.081, val_loss: 2.078 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 600/600 [00:07<00:00, 79.41it/s]\n",
      "epoch: 017 | val  : 100%|██████████| 258/258 [00:02<00:00, 96.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.079, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 600/600 [00:07<00:00, 82.09it/s]\n",
      "epoch: 018 | val  : 100%|██████████| 258/258 [00:02<00:00, 97.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.078, val_loss: 2.078 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train: 100%|██████████| 600/600 [00:07<00:00, 81.26it/s]\n",
      "epoch: 019 | val  : 100%|██████████| 258/258 [00:02<00:00, 99.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train_loss: 2.077, val_loss: 2.075 (best: 2.075)\n",
      "\n",
      "Best val_loss = 2.075 reached at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BS = 512\n",
    "lr = 3e-4\n",
    "num_epochs = 20\n",
    "device = 'cuda'\n",
    "hiddens = [128, 128, 128]\n",
    "dim_emb = 8\n",
    "\n",
    "train_dataset = Ratings(trainset, hidden_size=dim_emb)\n",
    "test_dataset = Ratings(testset, split='test', svd=train_dataset.svd)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BS, num_workers=0, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BS, num_workers=0, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "model = NCF(hiddens, dim_emb)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_losses_baseline, val_losses_baseline, best_val_loss_baseline, cnn_baseline = run_experiment(\n",
    "    model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs, device, '/content/drive/MyDrive/Ozon/NCF'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pyiV45ixbPf6",
    "outputId": "2c9ec9e5-08b4-4a35-9573-8cce28020bac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train:   0%|          | 0/600 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | train: 100%|█████████▉| 599/600 [00:09<00:00, 30.56it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([465])) that is different to the input size (torch.Size([465, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | train: 100%|██████████| 600/600 [00:09<00:00, 62.94it/s]\n",
      "epoch: 000 | val  :  99%|█████████▉| 255/258 [00:07<00:00, 37.60it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([53])) that is different to the input size (torch.Size([53, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | val  : 100%|██████████| 258/258 [00:07<00:00, 34.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 3.553, val_loss: 2.078 (best:   inf)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=00_valloss=2.078.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 600/600 [00:08<00:00, 70.99it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 258/258 [00:02<00:00, 100.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 2.250, val_loss: 2.078 (best: 2.078)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 600/600 [00:08<00:00, 71.09it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 258/258 [00:02<00:00, 94.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 2.172, val_loss: 2.075 (best: 2.078)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=02_valloss=2.075.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 600/600 [00:08<00:00, 70.62it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 258/258 [00:02<00:00, 94.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 2.142, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 600/600 [00:08<00:00, 72.18it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 258/258 [00:02<00:00, 101.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 2.130, val_loss: 2.076 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 600/600 [00:08<00:00, 71.82it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 258/258 [00:02<00:00, 100.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 2.124, val_loss: 2.076 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 600/600 [00:08<00:00, 71.02it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 258/258 [00:02<00:00, 98.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 2.119, val_loss: 2.075 (best: 2.075)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=06_valloss=2.075.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 600/600 [00:09<00:00, 60.40it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 258/258 [00:02<00:00, 94.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.114, val_loss: 2.076 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 600/600 [00:08<00:00, 70.45it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 258/258 [00:02<00:00, 94.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.109, val_loss: 2.079 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 600/600 [00:08<00:00, 72.08it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 258/258 [00:02<00:00, 94.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.105, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 600/600 [00:08<00:00, 71.37it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 258/258 [00:02<00:00, 97.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.101, val_loss: 2.075 (best: 2.075)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=10_valloss=2.075.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 600/600 [00:08<00:00, 72.23it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 258/258 [00:02<00:00, 94.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.097, val_loss: 2.075 (best: 2.075)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=11_valloss=2.075.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 600/600 [00:08<00:00, 70.76it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 258/258 [00:02<00:00, 97.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.093, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 600/600 [00:08<00:00, 71.20it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 258/258 [00:02<00:00, 96.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.089, val_loss: 2.076 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 600/600 [00:08<00:00, 71.84it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 258/258 [00:02<00:00, 103.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.086, val_loss: 2.077 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 600/600 [00:08<00:00, 72.23it/s]\n",
      "epoch: 015 | val  : 100%|██████████| 258/258 [00:02<00:00, 96.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.084, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 600/600 [00:08<00:00, 73.07it/s]\n",
      "epoch: 016 | val  : 100%|██████████| 258/258 [00:02<00:00, 97.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.082, val_loss: 2.078 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 600/600 [00:08<00:00, 71.99it/s]\n",
      "epoch: 017 | val  : 100%|██████████| 258/258 [00:02<00:00, 94.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.080, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 600/600 [00:09<00:00, 60.49it/s]\n",
      "epoch: 018 | val  : 100%|██████████| 258/258 [00:02<00:00, 94.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.079, val_loss: 2.077 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train: 100%|██████████| 600/600 [00:08<00:00, 69.63it/s]\n",
      "epoch: 019 | val  : 100%|██████████| 258/258 [00:02<00:00, 95.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train_loss: 2.078, val_loss: 2.076 (best: 2.075)\n",
      "\n",
      "Best val_loss = 2.075 reached at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BS = 512\n",
    "lr = 3e-4\n",
    "num_epochs = 20\n",
    "device = 'cuda'\n",
    "hiddens = [128, 128, 128]\n",
    "dim_emb = 10\n",
    "\n",
    "train_dataset = Ratings(trainset, hidden_size=dim_emb)\n",
    "test_dataset = Ratings(testset, split='test', svd=train_dataset.svd)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BS, num_workers=0, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BS, num_workers=0, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "model = NCF(hiddens, dim_emb)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_losses_baseline, val_losses_baseline, best_val_loss_baseline, cnn_baseline = run_experiment(\n",
    "    model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs, device, '/content/drive/MyDrive/Ozon/NCF'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yGxuNq74j3ms",
    "outputId": "ed603512-5acd-47f1-eb42-8eaafcef89f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|██████████| 600/600 [00:08<00:00, 72.16it/s]\n",
      "epoch: 000 | val  : 100%|██████████| 258/258 [00:02<00:00, 97.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 3.573, val_loss: 2.092 (best:   inf)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=00_valloss=2.092.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 600/600 [00:08<00:00, 73.32it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 258/258 [00:02<00:00, 100.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 2.243, val_loss: 2.078 (best: 2.092)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=01_valloss=2.078.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 600/600 [00:08<00:00, 70.84it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 258/258 [00:04<00:00, 58.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 2.163, val_loss: 2.076 (best: 2.078)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=02_valloss=2.076.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 600/600 [00:08<00:00, 72.72it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 258/258 [00:02<00:00, 97.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 2.136, val_loss: 2.076 (best: 2.076)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 600/600 [00:07<00:00, 77.28it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 258/258 [00:02<00:00, 106.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 2.128, val_loss: 2.080 (best: 2.076)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 600/600 [00:07<00:00, 75.69it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 258/258 [00:02<00:00, 106.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 2.123, val_loss: 2.075 (best: 2.076)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=05_valloss=2.075.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 600/600 [00:08<00:00, 74.43it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 258/258 [00:02<00:00, 99.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 2.117, val_loss: 2.077 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 600/600 [00:07<00:00, 77.29it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 258/258 [00:02<00:00, 101.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.113, val_loss: 2.076 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 600/600 [00:07<00:00, 77.07it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 258/258 [00:02<00:00, 98.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.109, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 600/600 [00:07<00:00, 76.28it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 258/258 [00:02<00:00, 99.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.104, val_loss: 2.076 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 600/600 [00:08<00:00, 74.25it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 258/258 [00:02<00:00, 105.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.099, val_loss: 2.075 (best: 2.075)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=10_valloss=2.075.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 600/600 [00:08<00:00, 74.66it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 258/258 [00:02<00:00, 106.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.096, val_loss: 2.075 (best: 2.075)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=11_valloss=2.075.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 600/600 [00:08<00:00, 73.94it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 258/258 [00:02<00:00, 100.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.092, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 600/600 [00:08<00:00, 74.96it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 258/258 [00:02<00:00, 97.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.089, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 600/600 [00:08<00:00, 73.93it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 258/258 [00:02<00:00, 97.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.086, val_loss: 2.081 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 600/600 [00:08<00:00, 73.99it/s]\n",
      "epoch: 015 | val  : 100%|██████████| 258/258 [00:02<00:00, 94.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.084, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 600/600 [00:07<00:00, 77.06it/s]\n",
      "epoch: 016 | val  : 100%|██████████| 258/258 [00:02<00:00, 101.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.082, val_loss: 2.075 (best: 2.075)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/NCF/epoch=16_valloss=2.075.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 600/600 [00:08<00:00, 74.48it/s]\n",
      "epoch: 017 | val  : 100%|██████████| 258/258 [00:02<00:00, 99.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.080, val_loss: 2.075 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 600/600 [00:07<00:00, 75.81it/s]\n",
      "epoch: 018 | val  : 100%|██████████| 258/258 [00:02<00:00, 99.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.079, val_loss: 2.079 (best: 2.075)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train: 100%|██████████| 600/600 [00:07<00:00, 75.42it/s]\n",
      "epoch: 019 | val  : 100%|██████████| 258/258 [00:02<00:00, 107.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train_loss: 2.078, val_loss: 2.079 (best: 2.075)\n",
      "\n",
      "Best val_loss = 2.075 reached at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BS = 512\n",
    "lr = 3e-4\n",
    "num_epochs = 20\n",
    "device = 'cpu'\n",
    "hiddens = [128, 128, 128]\n",
    "dim_emb = 12\n",
    "\n",
    "train_dataset = Ratings(trainset, hidden_size=dim_emb)\n",
    "test_dataset = Ratings(testset, split='test', svd=train_dataset.svd)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BS, num_workers=0, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BS, num_workers=0, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "model = NCF(hiddens, dim_emb)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_losses_baseline, val_losses_baseline, best_val_loss_baseline, cnn_baseline = run_experiment(\n",
    "    model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs, device, '/content/drive/MyDrive/Ozon/NCF'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSdYu8AnpafT"
   },
   "source": [
    "Как мы видим буквально все 3 сетки отрабатывают одинаково, я до этого пробовал сетки менее глубокие и решил что 2.075 связано с глубиной. Возможно это и так, но на текущем LR ниже не опускается. Обычно все методы с нейронками требуют танцев с бубнами над архитектурой и гиперпараметрами для каждой конкретной задачи, чтобы получить приемлемый результат. По экспериментам выше видим, что вне зависимости от подаваемых компонент скор не меняется. Как было видно в 1 задании, с увеличением параметров обычный SVD становился только хуже. Здесь мы такого не наблюдаем, спасибо нашей нейронке, но скор наш все равно ниже. Я опять же связываю это с глубиной и степенью работы над ней. Теоретически, добавляя больше компонент мы можем с одной стороны запутать нейронку, если вдруг эти компоненты будут неинформативные и ненужной, с другой стороны мы таким образом создаем больше степеней свободы и при хорошем обучении нейронка вполне может и занулить ненужные ей параметры.\n",
    "\n",
    "\n",
    "# Гибридная архитектура\n",
    "\n",
    "Ниже мы будем рассматривать гибридную архитектуру. Для нее будем пользоваться дополнительно признаками с айтема и с юзера. \n",
    "\n",
    "Логика будет следующая: признаки с айтема - это для конкретного айтема вектор из 5 его признаков\n",
    "признаки юзера - one-hot-encoding по айтемам, которые он добавил в избранное. То есть это вектор размера максимального айтема, где на месте i стоит 1 если пользователь добавил этот айтем в избранное\n",
    "\n",
    "А архитектура будет следующая:\n",
    " В первую очередь мы пропустим вектор информации по юзеру через один линейный слой, который будет играть роль эмбеддингового слоя. Таким образом мы получим скрытую репрезентацию его предпочтений исходя из его избранных фильмов.\n",
    "\n",
    " Далее возьмем вектора юзера и айтема из SVD, вектор признаков айтема, а также полученный выше эмбеддинг и сконкатенируем их в один вектор и далее пропустим через пару линейных слоев. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eB-vybnukWDE"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'catalogue.json'), 'r') as f:\n",
    "    catalogue = json.load(f)\n",
    "    \n",
    "catalogue = {int(k): v for k, v in catalogue.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYW374ESsux2"
   },
   "outputs": [],
   "source": [
    "bookmarks = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, 'bookmarks.csv'),\n",
    "    dtype={\n",
    "        'element_uid': np.uint16,\n",
    "        'user_uid': np.uint32,\n",
    "        'ts': np.float64\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Nl7x_JKHs58S",
    "outputId": "30707e89-fc47-4024-d19d-bc8f60813b96"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b58a3130-3166-4d72-99e0-e32ea9097194\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_uid</th>\n",
       "      <th>element_uid</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301135</td>\n",
       "      <td>7185</td>\n",
       "      <td>4.430516e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301135</td>\n",
       "      <td>4083</td>\n",
       "      <td>4.430516e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301135</td>\n",
       "      <td>10158</td>\n",
       "      <td>4.430516e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301135</td>\n",
       "      <td>2693</td>\n",
       "      <td>4.430516e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301135</td>\n",
       "      <td>2181</td>\n",
       "      <td>4.430515e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948211</th>\n",
       "      <td>524752</td>\n",
       "      <td>2557</td>\n",
       "      <td>4.173079e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948212</th>\n",
       "      <td>524752</td>\n",
       "      <td>8919</td>\n",
       "      <td>4.173077e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948213</th>\n",
       "      <td>5174</td>\n",
       "      <td>3637</td>\n",
       "      <td>4.173076e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948214</th>\n",
       "      <td>161137</td>\n",
       "      <td>9700</td>\n",
       "      <td>4.173076e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948215</th>\n",
       "      <td>26252</td>\n",
       "      <td>8460</td>\n",
       "      <td>4.173068e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>948216 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b58a3130-3166-4d72-99e0-e32ea9097194')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b58a3130-3166-4d72-99e0-e32ea9097194 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b58a3130-3166-4d72-99e0-e32ea9097194');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        user_uid  element_uid            ts\n",
       "0         301135         7185  4.430516e+07\n",
       "1         301135         4083  4.430516e+07\n",
       "2         301135        10158  4.430516e+07\n",
       "3         301135         2693  4.430516e+07\n",
       "4         301135         2181  4.430515e+07\n",
       "...          ...          ...           ...\n",
       "948211    524752         2557  4.173079e+07\n",
       "948212    524752         8919  4.173077e+07\n",
       "948213      5174         3637  4.173076e+07\n",
       "948214    161137         9700  4.173076e+07\n",
       "948215     26252         8460  4.173068e+07\n",
       "\n",
       "[948216 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gftFEr2M-yfv"
   },
   "source": [
    "Для более честной оценки, мы возьмем поюзерную информацию только ту, которая по времени шла раньше тестового датасета. Мы просто всю информацию после времени начала тестового датасета выкинем. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnYJZkiJ0wqL"
   },
   "outputs": [],
   "source": [
    "time_train = ratings['ts'][trainset.n_ratings]\n",
    "\n",
    "bm_train = bookmarks[(bookmarks['ts'] < time_train)]\n",
    "bm_train.index = np.arange(len(bm_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bFKyzIWusOn"
   },
   "outputs": [],
   "source": [
    "class Ratings(Dataset):\n",
    "    def __init__(self, df,  bookmarks, catalogue, split='train', svd=None, hidden_size=5):\n",
    "        \n",
    "        self.split = split\n",
    "\n",
    "\n",
    "        if split == 'train':\n",
    "            self.df = df\n",
    "            self.iter_df = list(df.all_ratings())\n",
    "        else:\n",
    "            self.iter_df = df\n",
    "\n",
    "        if split == 'train':\n",
    "            self.svd = SVD(n_factors=hidden_size)\n",
    "            self.svd.fit(self.df)\n",
    "        else:\n",
    "            self.svd = svd\n",
    "            self.meanpu = self.svd.pu.mean(axis=0)\n",
    "            self.meanqi = self.svd.qi.mean(axis=0)\n",
    "\n",
    "        self.bookmarks = bookmarks\n",
    "        self.catalogue = catalogue\n",
    "        self.max_iid = len(self.catalogue)\n",
    "\n",
    "    def __len__(self,):\n",
    "        \n",
    "        length = len(self.iter_df)\n",
    "\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.iter_df[idx]\n",
    "        r = torch.tensor(row[2])\n",
    "\n",
    "        user_id = row[0]\n",
    "        element_id = row[1]\n",
    "\n",
    "        try:\n",
    "            user_vector = self.svd.pu[user_id]\n",
    "        except IndexError:\n",
    "            user_vector = self.meanpu\n",
    "\n",
    "        try:\n",
    "            item_vector = self.svd.qi[element_id]\n",
    "        except IndexError:\n",
    "            item_vector = self.meanqi\n",
    "\n",
    "        if self.split == 'train':\n",
    "            user_raw_id = trainset.to_raw_uid(user_id)\n",
    "            item_raw_id = trainset.to_raw_iid(element_id)\n",
    "\n",
    "        else:\n",
    "            user_raw_id = user_id\n",
    "            item_raw_id = element_id\n",
    "\n",
    "        user_info = self.get_user_info(user_raw_id)\n",
    "        item_info = self.get_item_info(item_raw_id)\n",
    "\n",
    "\n",
    "        return torch.from_numpy(user_vector).float(), torch.from_numpy(item_vector).float(), r.float(), torch.from_numpy(user_info).float(), torch.from_numpy(item_info).float()\n",
    "\n",
    "\n",
    "    def get_user_info(self, user_raw_id):\n",
    "\n",
    "        zero_vec = np.zeros(self.max_iid)\n",
    "\n",
    "        bki = np.unique((self.bookmarks[(self.bookmarks['user_uid'] == user_raw_id)]['element_uid']).values).astype(np.int32)\n",
    "        zero_vec[bki] = 1\n",
    "\n",
    "        return zero_vec\n",
    "\n",
    "    def get_item_info(self, item_raw_id):\n",
    "\n",
    "        item_info = self.catalogue[item_raw_id]\n",
    "\n",
    "        vec_info =  np.array([item_info['feature_1'], item_info['feature_2'],item_info['feature_3'],item_info['feature_4'],item_info['feature_5']])\n",
    "\n",
    "        return vec_info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjwbLpeY2xpt"
   },
   "outputs": [],
   "source": [
    "class Hybrid(nn.Module):\n",
    "\n",
    "    def __init__(self, hiddens, embedding_dim, max_iid, user_info_emb_dim=32, activation_type='Relu'):\n",
    "        super(Hybrid, self).__init__()\n",
    "\n",
    "        #item info size = 5\n",
    "        #OHE user info size = max_iid\n",
    "        #user_x and item_x size = embedding_dim\n",
    "\n",
    "\n",
    "        self.first_dim = (2*embedding_dim + 5 + user_info_emb_dim)\n",
    "        model_hidden = []\n",
    "        self.hiddens = hiddens\n",
    "        n_layers = len(hiddens)\n",
    "\n",
    "        self.Emb = nn.Linear(max_iid, user_info_emb_dim, bias=False)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(self.first_dim, self.hiddens[0])\n",
    "\n",
    "        self.activation = torch.nn.ReLU(True)\n",
    "\n",
    "        for i in range(0, n_layers-1):\n",
    "            layer = nn.Sequential(nn.Dropout(p=0.3),\n",
    "          torch.nn.Linear(self.hiddens[i] ,self.hiddens[i+1]),\n",
    "          self.activation)\n",
    "            model_hidden.append(layer)\n",
    "\n",
    "        self.outLinear = nn.Linear(self.hiddens[-1], 1)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            self.linear1,\n",
    "            self.activation,\n",
    "            *model_hidden,\n",
    "            self.outLinear\n",
    "        )\n",
    "\n",
    "    def forward(self, user_x, item_x, item_info, user_info):\n",
    "\n",
    "        user_info_emb = self.Emb(user_info)\n",
    "\n",
    "        x = torch.cat((user_x, item_x, item_info, user_info_emb), dim=1)\n",
    "        \n",
    "\n",
    "        out = self.net(x)\n",
    "\n",
    "        return torch.clamp(out, min=0,max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkjUMVnh43g1"
   },
   "outputs": [],
   "source": [
    "def run_epoch(stage, model, dataloader, loss_fn, optimizer, epoch, device):\n",
    "\n",
    "    if stage == \"train\":\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "    else:\n",
    "        torch.set_grad_enabled(False)\n",
    "        model.eval()\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    losses = []\n",
    "    for batch in tqdm(dataloader, total=len(dataloader), desc=f\"epoch: {str(epoch).zfill(3)} | {stage:5}\"):\n",
    "        uid, eid, r, uinfo, iinfo = batch\n",
    "\n",
    "        uid = uid.to(device)\n",
    "        eid = eid.to(device)\n",
    "        uinfo = uinfo.to(device)\n",
    "        iinfo = iinfo.to(device)\n",
    "\n",
    "                \n",
    "        r_pred = model(uid, eid, iinfo, uinfo)\n",
    "\n",
    "        #r = r.to(torch.float32)\n",
    "        loss = loss_fn(r_pred, r.to(device)) #.float()\n",
    "       # print(loss.float())\n",
    "\n",
    "        if stage == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "        losses.append(loss.detach().cpu().item())\n",
    "    \n",
    "\n",
    "    return np.sqrt(np.mean(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-11c-SScB9mN"
   },
   "source": [
    "Здесь я намеренно сделал архитектуру менее глубокой, потому что иначе это учится пол года, сомневаюсь что настолько глубокую сеть я смогу выучить на ресурсах коллаба и 1 гпу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JikHUiZh4Pca",
    "outputId": "100af2b2-eaf0-478b-f712-0b5ba4fb482f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train: 100%|█████████▉| 599/600 [04:23<00:00,  2.42it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([465])) that is different to the input size (torch.Size([465, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | train: 100%|██████████| 600/600 [04:23<00:00,  2.28it/s]\n",
      "epoch: 000 | val  : 100%|█████████▉| 257/258 [01:47<00:00,  2.37it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([53])) that is different to the input size (torch.Size([53, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | val  : 100%|██████████| 258/258 [01:47<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 3.011, val_loss: 2.751 (best:   inf)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/Hybrid/epoch=00_valloss=2.751.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 600/600 [04:10<00:00,  2.40it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 258/258 [01:45<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 2.750, val_loss: 2.752 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 600/600 [04:11<00:00,  2.39it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 258/258 [01:46<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 2.750, val_loss: 2.753 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 600/600 [04:10<00:00,  2.40it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 258/258 [01:45<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 2.749, val_loss: 2.755 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 600/600 [04:10<00:00,  2.40it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 258/258 [01:46<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 2.749, val_loss: 2.756 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 600/600 [04:09<00:00,  2.40it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 258/258 [01:45<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 2.749, val_loss: 2.756 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 600/600 [04:09<00:00,  2.41it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 258/258 [01:46<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 2.749, val_loss: 2.756 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 600/600 [04:08<00:00,  2.42it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 258/258 [01:44<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.749, val_loss: 2.757 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 600/600 [04:07<00:00,  2.42it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 258/258 [01:44<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.749, val_loss: 2.757 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 600/600 [04:07<00:00,  2.42it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 258/258 [01:45<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.749, val_loss: 2.756 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train: 100%|██████████| 600/600 [04:08<00:00,  2.42it/s]\n",
      "epoch: 010 | val  : 100%|██████████| 258/258 [01:44<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 010 | train_loss: 2.749, val_loss: 2.756 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train: 100%|██████████| 600/600 [04:07<00:00,  2.43it/s]\n",
      "epoch: 011 | val  : 100%|██████████| 258/258 [01:44<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 011 | train_loss: 2.749, val_loss: 2.757 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train: 100%|██████████| 600/600 [04:06<00:00,  2.44it/s]\n",
      "epoch: 012 | val  : 100%|██████████| 258/258 [01:44<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 012 | train_loss: 2.749, val_loss: 2.756 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train: 100%|██████████| 600/600 [04:07<00:00,  2.43it/s]\n",
      "epoch: 013 | val  : 100%|██████████| 258/258 [01:44<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 013 | train_loss: 2.749, val_loss: 2.756 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train: 100%|██████████| 600/600 [04:06<00:00,  2.44it/s]\n",
      "epoch: 014 | val  : 100%|██████████| 258/258 [01:44<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 014 | train_loss: 2.749, val_loss: 2.757 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train: 100%|██████████| 600/600 [04:06<00:00,  2.43it/s]\n",
      "epoch: 015 | val  : 100%|██████████| 258/258 [01:44<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 015 | train_loss: 2.749, val_loss: 2.756 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train: 100%|██████████| 600/600 [04:07<00:00,  2.43it/s]\n",
      "epoch: 016 | val  : 100%|██████████| 258/258 [01:44<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 016 | train_loss: 2.749, val_loss: 2.757 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train: 100%|██████████| 600/600 [04:06<00:00,  2.43it/s]\n",
      "epoch: 017 | val  : 100%|██████████| 258/258 [01:45<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 017 | train_loss: 2.749, val_loss: 2.757 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train: 100%|██████████| 600/600 [04:06<00:00,  2.43it/s]\n",
      "epoch: 018 | val  : 100%|██████████| 258/258 [01:44<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 018 | train_loss: 2.749, val_loss: 2.756 (best: 2.751)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 019 | train:  22%|██▏       | 133/600 [00:55<03:08,  2.47it/s]"
     ]
    }
   ],
   "source": [
    "BS = 512\n",
    "lr = 3e-4\n",
    "num_epochs = 20\n",
    "device = 'cuda'\n",
    "hiddens = [64, 64]\n",
    "dim_emb = 8\n",
    "max_iid = len(catalogue)\n",
    "user_info_emb_dim = 32\n",
    "\n",
    "train_dataset = Ratings(trainset, bm_train, catalogue, hidden_size=dim_emb)\n",
    "test_dataset = Ratings(testset, bm_train, catalogue, split='test', svd=train_dataset.svd)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BS, num_workers=0, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BS, num_workers=0, shuffle=False)\n",
    "\n",
    "model = Hybrid(hiddens, dim_emb, max_iid, user_info_emb_dim=user_info_emb_dim)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_losses_baseline, val_losses_baseline, best_val_loss_baseline, cnn_baseline = run_experiment(\n",
    "    model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs, device, '/content/drive/MyDrive/Ozon/Hybrid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7a5ATqG4u8x",
    "outputId": "c805aae0-51cf-40ea-c093-3b9ca738a023"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train:   0%|          | 0/600 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | train: 100%|█████████▉| 599/600 [04:22<00:00,  2.35it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([465])) that is different to the input size (torch.Size([465, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | train: 100%|██████████| 600/600 [04:23<00:00,  2.28it/s]\n",
      "epoch: 000 | val  : 100%|█████████▉| 257/258 [01:47<00:00,  2.43it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([53])) that is different to the input size (torch.Size([53, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | val  : 100%|██████████| 258/258 [01:47<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 2.816, val_loss: 2.741 (best:   inf)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/Hybrid/epoch=00_valloss=2.741.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 600/600 [04:13<00:00,  2.37it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 258/258 [01:47<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 2.754, val_loss: 2.745 (best: 2.741)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 600/600 [04:07<00:00,  2.42it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 258/258 [01:44<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 2.754, val_loss: 2.748 (best: 2.741)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 600/600 [04:06<00:00,  2.43it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 258/258 [01:43<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 2.754, val_loss: 2.747 (best: 2.741)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 600/600 [04:06<00:00,  2.44it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 258/258 [01:44<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 2.754, val_loss: 2.754 (best: 2.741)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 600/600 [04:04<00:00,  2.45it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 258/258 [01:43<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 2.754, val_loss: 2.753 (best: 2.741)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 600/600 [04:04<00:00,  2.46it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 258/258 [01:47<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 2.754, val_loss: 2.752 (best: 2.741)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 600/600 [04:02<00:00,  2.48it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 258/258 [01:43<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.754, val_loss: 2.753 (best: 2.741)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 600/600 [04:02<00:00,  2.47it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 258/258 [01:46<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.754, val_loss: 2.752 (best: 2.741)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 600/600 [04:02<00:00,  2.47it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 258/258 [01:50<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.754, val_loss: 2.753 (best: 2.741)\n",
      "\n",
      "Best val_loss = 2.741 reached at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BS = 512\n",
    "lr = 3e-4\n",
    "num_epochs = 10\n",
    "device = 'cuda'\n",
    "hiddens = [64, 64]\n",
    "dim_emb = 10\n",
    "max_iid = len(catalogue)\n",
    "user_info_emb_dim = 32\n",
    "\n",
    "train_dataset = Ratings(trainset, bm_train, catalogue, hidden_size=dim_emb)\n",
    "test_dataset = Ratings(testset, bm_train, catalogue, split='test', svd=train_dataset.svd)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BS, num_workers=0, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BS, num_workers=0, shuffle=False)\n",
    "\n",
    "model = Hybrid(hiddens, dim_emb, max_iid, user_info_emb_dim=user_info_emb_dim)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_losses_baseline, val_losses_baseline, best_val_loss_baseline, cnn_baseline = run_experiment(\n",
    "    model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs, device, '/content/drive/MyDrive/Ozon/Hybrid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "CztA1pstiAuV",
    "outputId": "89416576-35b8-426b-fe4e-59c002df7ab5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train:   0%|          | 0/600 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | train: 100%|█████████▉| 599/600 [05:56<00:00,  1.41it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([465])) that is different to the input size (torch.Size([465, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | train: 100%|██████████| 600/600 [05:56<00:00,  1.68it/s]\n",
      "epoch: 000 | val  : 100%|█████████▉| 257/258 [02:26<00:00,  1.81it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([53])) that is different to the input size (torch.Size([53, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "epoch: 000 | val  : 100%|██████████| 258/258 [02:26<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000 | train_loss: 2.784, val_loss: 2.738 (best:   inf)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/Hybrid/epoch=00_valloss=2.738.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train: 100%|██████████| 600/600 [05:34<00:00,  1.79it/s]\n",
      "epoch: 001 | val  : 100%|██████████| 258/258 [02:16<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001 | train_loss: 2.755, val_loss: 2.738 (best: 2.738)\n",
      "New checkpoint saved to /content/drive/MyDrive/Ozon/Hybrid/epoch=01_valloss=2.738.pth.tar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train: 100%|██████████| 600/600 [05:25<00:00,  1.84it/s]\n",
      "epoch: 002 | val  : 100%|██████████| 258/258 [02:14<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 002 | train_loss: 2.754, val_loss: 2.742 (best: 2.738)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train: 100%|██████████| 600/600 [05:27<00:00,  1.83it/s]\n",
      "epoch: 003 | val  : 100%|██████████| 258/258 [02:19<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 003 | train_loss: 2.754, val_loss: 2.742 (best: 2.738)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train: 100%|██████████| 600/600 [05:34<00:00,  1.80it/s]\n",
      "epoch: 004 | val  : 100%|██████████| 258/258 [02:25<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 004 | train_loss: 2.754, val_loss: 2.745 (best: 2.738)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train: 100%|██████████| 600/600 [05:31<00:00,  1.81it/s]\n",
      "epoch: 005 | val  : 100%|██████████| 258/258 [02:19<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 005 | train_loss: 2.754, val_loss: 2.747 (best: 2.738)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train: 100%|██████████| 600/600 [05:30<00:00,  1.82it/s]\n",
      "epoch: 006 | val  : 100%|██████████| 258/258 [02:21<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 006 | train_loss: 2.754, val_loss: 2.749 (best: 2.738)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train: 100%|██████████| 600/600 [05:41<00:00,  1.76it/s]\n",
      "epoch: 007 | val  : 100%|██████████| 258/258 [02:27<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 007 | train_loss: 2.754, val_loss: 2.750 (best: 2.738)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train: 100%|██████████| 600/600 [05:51<00:00,  1.71it/s]\n",
      "epoch: 008 | val  : 100%|██████████| 258/258 [02:44<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 008 | train_loss: 2.754, val_loss: 2.751 (best: 2.738)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train: 100%|██████████| 600/600 [06:29<00:00,  1.54it/s]\n",
      "epoch: 009 | val  : 100%|██████████| 258/258 [02:42<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 009 | train_loss: 2.754, val_loss: 2.755 (best: 2.738)\n",
      "\n",
      "Best val_loss = 2.738 reached at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BS = 512\n",
    "lr = 3e-4\n",
    "num_epochs = 10\n",
    "device = 'cpu'\n",
    "hiddens = [64, 64]\n",
    "dim_emb = 12\n",
    "max_iid = len(catalogue)\n",
    "user_info_emb_dim = 32\n",
    "\n",
    "train_dataset = Ratings(trainset, bm_train, catalogue, hidden_size=dim_emb)\n",
    "test_dataset = Ratings(testset, bm_train, catalogue, split='test', svd=train_dataset.svd)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BS, num_workers=0, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BS, num_workers=0, shuffle=False)\n",
    "\n",
    "model = Hybrid(hiddens, dim_emb, max_iid, user_info_emb_dim=user_info_emb_dim)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_losses_baseline, val_losses_baseline, best_val_loss_baseline, cnn_baseline = run_experiment(\n",
    "    model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs, device, '/content/drive/MyDrive/Ozon/Hybrid'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUDwuOj-E47G"
   },
   "source": [
    "Из проведенных выше экспериментов видим, что качество у трех гибридных сетей примерно на одной уровне, при этом не на очень хорошем, RMSE = 2.74, конечно это связано с тем как мы обучаем сеть. Возможно ей было тяжеловато выучиться на не очень глубокой сети, может размер эмбеддинга был маловат для юзер-инфо, может дропаут слишком много выкидывал важного и мы не смогли обучить. Моя гипотеза в том, что здесь дело исключительно в архитектуре. Предположительно можно подавать часть этих признаков не вначале, а в конце, например признаки объекта, возможно они не нуждаются ни в каких трансформациях.\n",
    "\n",
    "\n",
    "По итогу экспериментов видим, что лучшим оказался SVD, но это несомненно связано с тем как мы обучаем сеть. Мы точно знаем, что подавая на вход разложения из SVD при корректном обучении мы точно получим сеть не хуже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
